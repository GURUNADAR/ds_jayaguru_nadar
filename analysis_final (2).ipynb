{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017108dc",
   "metadata": {},
   "source": [
    "# Trader Behaviour & Market Sentiment Analysis (Complete)\n",
    "\n",
    "This notebook is simple and beginner-friendly. Run cells sequentially. All visuals will be saved to `visual_insights/` and textual insights to `insights_summary.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21946cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, os, math\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e34de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data files (they must be in the same folder as this notebook)\n",
    "sentiment_df = pd.read_csv('market_sentiment.csv', low_memory=False)\n",
    "trader_df = pd.read_csv('trader_behaviour.csv', low_memory=False)\n",
    "\n",
    "# clean column names\n",
    "sentiment_df.columns = [str(c).strip().lower().replace(' ', '_') for c in sentiment_df.columns]\n",
    "trader_df.columns = [str(c).strip().lower().replace(' ', '_') for c in trader_df.columns]\n",
    "\n",
    "print('Sentiment columns:', sentiment_df.columns.tolist())\n",
    "print('Trader columns:', trader_df.columns.tolist())\n",
    "\n",
    "display(sentiment_df.head())\n",
    "display(trader_df.head())\n",
    "\n",
    "# create visual_insights folder\n",
    "os.makedirs('visual_insights', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbcaef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets on floored date (daily merge)\n",
    "date_cols_sent = [c for c in sentiment_df.columns if 'timestamp' in c or 'date' in c or 'time' in c]\n",
    "date_cols_trad = [c for c in trader_df.columns if 'timestamp' in c or 'date' in c or 'time' in c]\n",
    "\n",
    "if date_cols_sent:\n",
    "    sentiment_df['_dt'] = pd.to_datetime(sentiment_df[date_cols_sent[0]], errors='coerce')\n",
    "else:\n",
    "    sentiment_df['_dt'] = pd.NaT\n",
    "if date_cols_trad:\n",
    "    trader_df['_dt'] = pd.to_datetime(trader_df[date_cols_trad[0]], errors='coerce')\n",
    "else:\n",
    "    trader_df['_dt'] = pd.NaT\n",
    "\n",
    "sentiment_df['_date'] = sentiment_df['_dt'].dt.floor('d')\n",
    "trader_df['_date'] = trader_df['_dt'].dt.floor('d')\n",
    "\n",
    "merged_df = pd.merge(trader_df, sentiment_df, left_on='_date', right_on='_date', how='left', suffixes=('_trader','_sent'))\n",
    "print('Merged shape:', merged_df.shape)\n",
    "display(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd53399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations (each plot is saved to visual_insights/)\n",
    "# Detect numeric sentiment column\n",
    "sentiment_col = None\n",
    "for c in sentiment_df.select_dtypes(include=[np.number]).columns:\n",
    "    if 'sentiment' in c:\n",
    "        sentiment_col = c; break\n",
    "if sentiment_col is None:\n",
    "    if 'value' in sentiment_df.columns and pd.api.types.is_numeric_dtype(sentiment_df['value']):\n",
    "        sentiment_col = 'value'\n",
    "    else:\n",
    "        num_cols = sentiment_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        sentiment_col = num_cols[0] if num_cols else None\n",
    "\n",
    "# Detect target column\n",
    "target_col = None\n",
    "for cand in ['closed_pnl','pnl','profit','value']:\n",
    "    if cand in merged_df.columns:\n",
    "        target_col = cand; break\n",
    "if target_col is None:\n",
    "    numeric_candidates = [c for c in trader_df.select_dtypes(include=[np.number]).columns if trader_df[c].nunique() > 1]\n",
    "    target_col = numeric_candidates[-1] if numeric_candidates else None\n",
    "\n",
    "# Create 'profitable' boolean if possible\n",
    "if target_col and pd.api.types.is_numeric_dtype(merged_df[target_col]):\n",
    "    merged_df['profitable'] = merged_df[target_col] > 0\n",
    "else:\n",
    "    merged_df['profitable'] = np.nan\n",
    "\n",
    "# Helper to save plots\n",
    "def save_plot(path):\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "\n",
    "# 1) PnL distribution\n",
    "if target_col and target_col in merged_df.columns and pd.api.types.is_numeric_dtype(merged_df[target_col]):\n",
    "    data = merged_df[target_col].dropna()\n",
    "    if len(data)>0:\n",
    "        plt.figure(figsize=(8,5))\n",
    "        lower, upper = np.percentile(data,1), np.percentile(data,99)\n",
    "        plt.hist(data.clip(lower, upper), bins=80)\n",
    "        plt.title('Distribution of closed PnL (1-99 pct clipped)')\n",
    "        plt.xlabel('closed_pnl'); plt.ylabel('count')\n",
    "        save_plot('visual_insights/pnl_distribution.png')\n",
    "        display(plt.imread('visual_insights/pnl_distribution.png'))\n",
    "\n",
    "# 2) Sentiment trend\n",
    "if sentiment_col and sentiment_col in sentiment_df.columns:\n",
    "    s_daily = sentiment_df.groupby(sentiment_df['_date'])[sentiment_col].mean().dropna()\n",
    "    if len(s_daily)>0:\n",
    "        plt.figure(figsize=(10,4))\n",
    "        s_daily.plot()\n",
    "        plt.title('Sentiment trend (daily mean)'); plt.xlabel('date'); plt.ylabel(sentiment_col)\n",
    "        save_plot('visual_insights/sentiment_trend.png')\n",
    "        display(plt.imread('visual_insights/sentiment_trend.png'))\n",
    "\n",
    "# 3) Performance vs Sentiment scatter\n",
    "if sentiment_col and sentiment_col in merged_df.columns and target_col and target_col in merged_df.columns:\n",
    "    sub = merged_df[[sentiment_col, target_col]].dropna()\n",
    "    if len(sub)>0:\n",
    "        if len(sub)>20000: sub = sub.sample(20000, random_state=42)\n",
    "        plt.figure(figsize=(7,5))\n",
    "        plt.scatter(sub[sentiment_col], sub[target_col], alpha=0.3, s=10)\n",
    "        plt.title('Performance vs Sentiment (scatter)'); plt.xlabel(sentiment_col); plt.ylabel(target_col)\n",
    "        save_plot('visual_insights/performance_vs_sentiment.png')\n",
    "        display(plt.imread('visual_insights/performance_vs_sentiment.png'))\n",
    "\n",
    "# 4) Correlation heatmap (numeric only)\n",
    "numeric_df = merged_df.select_dtypes(include=['number'])\n",
    "if not numeric_df.empty:\n",
    "    corr = numeric_df.corr()\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.imshow(corr, aspect='auto')\n",
    "    plt.colorbar(); plt.title('Correlation matrix (numeric cols)')\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90, fontsize=8)\n",
    "    plt.yticks(range(len(corr.index)), corr.index, fontsize=8)\n",
    "    save_plot('visual_insights/correlation_heatmap.png')\n",
    "    display(plt.imread('visual_insights/correlation_heatmap.png'))\n",
    "\n",
    "# 5) Trade side distribution\n",
    "if 'side' in merged_df.columns:\n",
    "    vc = merged_df['side'].fillna('unknown').value_counts()\n",
    "    if len(vc)>0:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        vc.plot(kind='bar')\n",
    "        plt.title('Trade Side Distribution'); plt.xlabel('side'); plt.ylabel('count')\n",
    "        save_plot('visual_insights/trade_side_distribution.png')\n",
    "        display(plt.imread('visual_insights/trade_side_distribution.png'))\n",
    "\n",
    "# 6) Average performance per sentiment quartile\n",
    "if sentiment_col and sentiment_col in merged_df.columns and target_col and target_col in merged_df.columns:\n",
    "    tmp = merged_df[[sentiment_col, target_col]].dropna()\n",
    "    try:\n",
    "        if tmp[sentiment_col].nunique()>1:\n",
    "            tmp['sent_q'] = pd.qcut(tmp[sentiment_col], 4, labels=False, duplicates='drop')\n",
    "            grp = tmp.groupby('sent_q')[target_col].mean()\n",
    "            plt.figure(figsize=(6,4))\n",
    "            grp.plot(kind='bar'); plt.title('Average performance per sentiment quartile (0=low)')\n",
    "            plt.xlabel('sentiment_quartile'); plt.ylabel(f'avg {target_col}')\n",
    "            save_plot('visual_insights/avg_perf_per_sentiment_quartile.png')\n",
    "            display(plt.imread('visual_insights/avg_perf_per_sentiment_quartile.png'))\n",
    "    except Exception as e:\n",
    "        print('Could not compute quartiles:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c879867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple models (optional) - regression on closed_pnl and classification on 'profitable'\n",
    "# Prepare numeric features (drop ids and timestamps)\n",
    "feature_df = merged_df.select_dtypes(include=['number']).copy()\n",
    "for c in ['_date','_dt']:\n",
    "    if c in feature_df.columns: feature_df = feature_df.drop(columns=[c])\n",
    "# drop target from features\n",
    "targets = [c for c in ['closed_pnl','pnl','profit','value'] if c in merged_df.columns]\n",
    "target_col = targets[0] if targets else None\n",
    "\n",
    "if target_col and target_col in merged_df.columns:\n",
    "    if target_col in feature_df.columns: feature_df = feature_df.drop(columns=[target_col])\n",
    "# keep columns with variation\n",
    "feature_df = feature_df.loc[:, feature_df.nunique() > 1]\n",
    "\n",
    "# Regression\n",
    "if target_col and target_col in merged_df.columns and pd.api.types.is_numeric_dtype(merged_df[target_col]) and feature_df.shape[1]>0:\n",
    "    df_reg = merged_df[[target_col]].join(feature_df).dropna()\n",
    "    if len(df_reg) > 200:\n",
    "        y = df_reg[target_col].values\n",
    "        X = df_reg.drop(columns=[target_col]).values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        lr = LinearRegression(); lr.fit(X_train, y_train)\n",
    "        y_pred = lr.predict(X_test)\n",
    "        print('Regression MSE:', mean_squared_error(y_test, y_pred), 'R2:', r2_score(y_test, y_pred))\n",
    "        # save scatter plot\n",
    "        plt.figure(figsize=(6,5)); plt.scatter(y_test, y_pred, alpha=0.3, s=10); plt.xlabel('Actual'); plt.ylabel('Predicted'); plt.title('Linear Regression: Actual vs Pred')\n",
    "        plt.tight_layout(); plt.savefig('visual_insights/regression_actual_vs_predicted.png'); plt.show()\n",
    "    else:\n",
    "        print('Not enough data for regression (need >200 rows after dropna).')\n",
    "\n",
    "# Classification on 'profitable'\n",
    "if 'profitable' in merged_df.columns and merged_df['profitable'].notna().any() and feature_df.shape[1]>0:\n",
    "    df_clf = merged_df[['profitable']].join(feature_df).dropna()\n",
    "    if len(df_clf) > 200 and df_clf['profitable'].nunique() > 1:\n",
    "        y = df_clf['profitable'].astype(int).values\n",
    "        X = df_clf.drop(columns=['profitable']).values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "        clf = LogisticRegression(max_iter=1000); clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print('Classification accuracy:', accuracy_score(y_test, y_pred))\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        fig, ax = plt.subplots(figsize=(5,4)); disp.plot(ax=ax); plt.title('Logistic Regression Confusion Matrix')\n",
    "        plt.tight_layout(); plt.savefig('visual_insights/clf_confusion_matrix.png'); plt.show()\n",
    "    else:\n",
    "        print('Not enough data for classification or only one class present.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c31f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textual insights (auto-save)\n",
    "insights = []\n",
    "insights.append('Report generated: ' + datetime.utcnow().isoformat() + ' UTC')\n",
    "insights.append('Basic dataset sizes:')\n",
    "insights.append(' - market_sentiment rows: ' + str(len(sentiment_df)))\n",
    "insights.append(' - trader_behaviour rows: ' + str(len(trader_df)))\n",
    "insights.append(' - merged rows: ' + str(len(merged_df)))\n",
    "insights.append('')\n",
    "\n",
    "# detect sentiment and target\n",
    "sent_cols = [c for c in sentiment_df.select_dtypes(include=[np.number]).columns]\n",
    "sentiment_col = None\n",
    "for c in sent_cols:\n",
    "    if 'sentiment' in c:\n",
    "        sentiment_col = c; break\n",
    "if sentiment_col is None:\n",
    "    if 'value' in sentiment_df.columns and pd.api.types.is_numeric_dtype(sentiment_df['value']):\n",
    "        sentiment_col = 'value'\n",
    "    else:\n",
    "        sentiment_col = sent_cols[0] if sent_cols else None\n",
    "\n",
    "targets = [c for c in ['closed_pnl','pnl','profit','value'] if c in merged_df.columns]\n",
    "target_col = targets[0] if targets else None\n",
    "\n",
    "insights.append('Detected sentiment column: ' + str(sentiment_col))\n",
    "insights.append('Detected performance column: ' + str(target_col))\n",
    "insights.append('')\n",
    "\n",
    "# target stats\n",
    "if target_col and target_col in merged_df.columns and pd.api.types.is_numeric_dtype(merged_df[target_col]):\n",
    "    desc = merged_df[target_col].describe()\n",
    "    insights.append('Summary stats for ' + target_col + ':')\n",
    "    for k in ['count','mean','std','min','25%','50%','75%','max']:\n",
    "        if k in desc.index:\n",
    "            insights.append(f'  {k}: {desc[k]}')\n",
    "    insights.append('')\n",
    "\n",
    "# sentiment vs performance\n",
    "if sentiment_col and sentiment_col in merged_df.columns and target_col and target_col in merged_df.columns:\n",
    "    valid = merged_df[[sentiment_col, target_col]].dropna()\n",
    "    if len(valid)>0 and valid[sentiment_col].nunique()>1:\n",
    "        corr_val = valid[sentiment_col].corr(valid[target_col])\n",
    "        insights.append('Correlation between ' + sentiment_col + ' and ' + target_col + ': ' + str(round(corr_val,4)))\n",
    "        try:\n",
    "            q75 = valid[sentiment_col].quantile(0.75); q25 = valid[sentiment_col].quantile(0.25)\n",
    "            top_mean = valid[valid[sentiment_col] >= q75][target_col].mean()\n",
    "            bot_mean = valid[valid[sentiment_col] <= q25][target_col].mean()\n",
    "            insights.append('Average ' + target_col + ' in top sentiment quartile: ' + str(top_mean))\n",
    "            insights.append('Average ' + target_col + ' in bottom sentiment quartile: ' + str(bot_mean))\n",
    "            if not math.isclose(bot_mean, 0.0):\n",
    "                pct_change = ((top_mean - bot_mean) / abs(bot_mean)) * 100\n",
    "                insights.append('Percent change (top vs bottom): ' + str(round(pct_change,2)) + '%')\n",
    "            else:\n",
    "                insights.append('Percent change (top vs bottom): undefined (bottom mean is ~0)')\n",
    "        except Exception as e:\n",
    "            insights.append('Could not compute quartile comparison: ' + str(e))\n",
    "    else:\n",
    "        insights.append('Not enough variation in sentiment to compute correlation/quartiles.')\n",
    "else:\n",
    "    insights.append('Sentiment or performance column missing; skipping relationship insights.')\n",
    "\n",
    "# profitable counts\n",
    "if 'profitable' in merged_df.columns and merged_df['profitable'].notna().any():\n",
    "    prof_counts = merged_df['profitable'].value_counts(dropna=True)\n",
    "    insights.append('Profitable trade counts:')\n",
    "    for k,v in prof_counts.items():\n",
    "        insights.append(f'  {k}: {v}')\n",
    "\n",
    "with open('insights_summary.txt','w',encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(insights))\n",
    "\n",
    "print('Saved insights_summary.txt and correlation_matrix.csv (if numeric columns present)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0845b14b",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "All visuals are saved to `visual_insights/`. Insights are saved to `insights_summary.txt`. Run each cell sequentially."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
